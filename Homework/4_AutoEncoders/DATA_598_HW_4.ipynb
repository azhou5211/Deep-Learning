{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cde2f05",
   "metadata": {},
   "source": [
    "# \n",
    "<center><h1> Homework 4: AutoEncoders\n",
    "<center> Apoorv Sharma </center>\n",
    "    <center> DATA 598 (Winter 2022), University of Washington </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6450ee83",
   "metadata": {},
   "source": [
    "# 1. Denoising AutoEncoders and Step Decay Learning Rates\n",
    "\n",
    "In this exercise, we will use autoencoders to denoise (= de-noise, or remove the noise from) an image. We will also implement a step decay learning rate, a commonly used trick (for all deep kinds of deep nets, not just autoencoders).\n",
    "\n",
    "Suppose we have and image x and *corrupt* it by some means to get $x' = C(x)$. Example corruptions including adding Gaussian noise or deleting random pataches in the image. A denoising autoencoder with encoder $h_w$ and decoder $g_v$ (with respective parameters w and v) takes in the corrupted input $x'$ and returns $\\hat{x} = g(h(x'))$ that approximates the noise-less image x.\n",
    "\n",
    "We will train a denoising autoencoder to reconstruct the noiseless images from the noisy ones, by minimizing the corresponding reconstruction error:\n",
    "\n",
    "$$\n",
    "\\min_{w,v} \\mathbb{E} \\left|\\left| x - g_v \\circ h_w(C(x')) \\right|\\right|^2\n",
    "$$\n",
    "\n",
    "We will use a step decay learning rate schedule\n",
    "\n",
    "$$\n",
    "\\gamma_t = \\frac{\\gamma_0}{2^{\\lfloor t/t_o \\rfloor}}\n",
    "$$\n",
    "\n",
    "in epoch $t$, where $\\gamma_0$ is a given initial learning rate, and $t_0$ threshold. The learning is cut by a factor of 2 every $t_0$ epochs:\n",
    "\n",
    "$$\n",
    "\\gamma_0 \\dots \\gamma_0, \\frac{\\gamma_0}{2} \\dots \\frac{\\gamma_0}{2}, \\frac{\\gamma_0}{4} \\dots \\frac{\\gamma_0}{4}\n",
    "$$\n",
    "\n",
    "A larger learning rate makes faster progress initially whereas a smaller learning rate is more helpful closer\n",
    "to convergence. The step-decay schedule aims to get the best of both worlds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7589991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import relu\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3852bd",
   "metadata": {},
   "source": [
    "### Download and Process MINST dataset\n",
    "Perform the same preprocessing as in this weekâ€™s lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcc04d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = torch.Size([6000, 28, 28])\n",
      "n_train: 6000, n_test: 10000\n",
      "Image size: torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "# download dataset (~117M in size)\n",
    "train_dataset = MNIST('./data', train=True, download=True)\n",
    "X_train = train_dataset.data # torch tensor of type uint8\n",
    "y_train = train_dataset.targets # torch tensor of type Long\n",
    "test_dataset = MNIST('./data', train=False, download=True)\n",
    "X_test = test_dataset.data\n",
    "y_test = test_dataset.targets\n",
    "\n",
    "# choose a subsample of 10% of the data:\n",
    "idxs_train = torch.from_numpy(\n",
    "    np.random.choice(X_train.shape[0], replace=False, size=X_train.shape[0]//10)).long()\n",
    "X_train, y_train = X_train[idxs_train], y_train[idxs_train]\n",
    "# idxs_test = torch.from_numpy(\n",
    "#     np.random.choice(X_test.shape[0], replace=False, size=X_test.shape[0]//10))\n",
    "# X_test, y_test = X_test[idxs_test], y_test[idxs_test]\n",
    "\n",
    "print(f'X_train.shape = {X_train.shape}')\n",
    "print(f'n_train: {X_train.shape[0]}, n_test: {X_test.shape[0]}')\n",
    "print(f'Image size: {X_train.shape[1:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6e4636b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABH4AAAD0CAYAAADt0eG0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlb0lEQVR4nO3de7RlZXkn6t8HRDxyUS5yOUiAICQaE4ghIqINqCggBDQDle6OMDRihpgTczqJGjmHkiRDiYpJRhszaLEL+9AKAW2NgmgYKCEJINgoV0WxaAsRUEBuQW7f+WMt0puq/e3ae+11mTX384yxxto13z3nfPdi/2rqW3Otr9RaAwAAAED/bDLrBgAAAACYDIMfAAAAgJ4y+AEAAADoKYMfAAAAgJ4y+AEAAADoKYMfAAAAgJ4y+OmYUsrqUkotpew+wXOsGp7j4EmdA/pGNqGbZBO6STahm2RzZTL4GcHwl7jOuo8+KKU8q5TyR6WUs0spN5RSHhu+vq+cdW9sfGRzfEopBz/5ejYeH5h1j2w8ZHN8XDcZJ9kcH9dNxkk2x6+U8nOllP+rlHJFKeWnpZQHSynfKaV8spTy7Fn3N2mbzboBVrzdk/zF8Ou1SX6cZMeZdQOs62tJvjrP9sum3AcwsHtcN6HLXDehY0op2ya5MMmLknwjySeSPJJk1ySvzOA6etfMGpwCgx9m7dYMwvY/a613l1JWJzl+ti0Bc3y11rpq1k0A/8Z1E7rNdRO655MZDH3eXmv92NxCKaVkBbwTqvc/4KyVUo4ppfx/w9vIHiylPFBKuXp4m9lCr/8mpZT/u5RyUynl4VLK2lLKR0opWzfO85xSyn8updxSSvlZKeUnpZTPl1J+Y0I/2ljUWu+ptV5ca7171r2wssgmdJNsLsx1k1mRTegm2VxYKeXlSV6T5Lx1hz5JUgcen35n0+WOn8n7QJInklyR5LYkz0zy8iR/leQ3kvx2Y7+PJPl3Sc5N8rkkr07yziQvK6W8tNb68JPfWEp5YZIvJ9k2yUVJPpNk+yTHJLmslPLaWusF4/7BYCMnm4vz3FLKO5JsneRHSf6x1nrzjHui32QTukk2F8d1k2mTzYX9++Hz6lLKjkmOTLJDBvn8cq31tpl1NkUGP5P3mlrr9+ZuGE5e/2uSN5VS/nOt9Yp59jswyb611luH+7wnyd8leV2SP0ryp8Ptm2UQ1i2THFJr/dqc8/yfSb6e5MxSyu611p+N8gOUUvbNINRL8Ze11ntHOR9MiWwuzn8YPuae9/wkb6213rPEc8NiyCZ0k2wujusm0yabC3vyjqS9M/g5njGn9mgp5dRa658t8dwbn1qrxxIfSergpVvWMV44PM7/u8721cPt/888+/xCkseTfH/OtqOH3//Bxnl+f1g/Ys62VcNtBy+y1xOe/JmX8Nh9xNflyZ//lbP+7+yx8T1kc3zZTPLLSd6V5AUZXOi3T3JYBh+IVzP4kMpNZv3f3GPjeMim66ZHNx+y6brp0c2HbI41m7cPv/+xDD7r57kZ3BX12iR3DGsnzPq/+aQf7viZsFLKdhlMTI/IIEhbrPMtuzR2/dq6G2qtt5RSfpBk91LKs+pgwnnAsLxbKWXVPMfZa/j8vCQj3X5Xa12dwV8Q0BuyucFjX5/k+jmbHkjypVLKPye5JoN/JToqg1uDYWxkE7pJNjd4bNdNZkI2N2jT4fP/THJ8HU6Dkny2lPJYks8nec8Ez98JBj8TVEp5Vga3vu2R5MoMJox3ZzBtfFYG09HNG7vf0dj+oyS7ZTClvDfJdsPtx26gnS0X1zX0n2yOrtZ6Xynlvyd5bwbvC/c/YBkb2YRuks3RuW4ySbK5KPckeXaS/zFn6POkL2awrPvepZRn1lp/OvXupsTgZ7J+J4MQvq+us6xjKeWADILYsmOSb8+zfafh80/XeT661vr50Vtt81kF9JBsLs9dw+d1/0UJlks2oZtkc3lcN5kU2dywb2fw+T7rfW+t9YlSyn0ZvDXz/8j//ll7x+Bnsp47fD5/ntpBG9j3oCSXzt1QSvmFJLsmWTPnl/zy4fPLMrhNbRL2TXLKEvdZnXnCBR0hm8vz4uHzLcs8DqxLNqGbZHN5XDeZFNncsIszeJvlC9YtDFf52j7Jg0l+vMTzb1Q2mXUDPbdm+Hzw3I2llF/L4H2EC/n9Uspuc/bZJMkHM/hv9l/nfN/nknwvyUmllCPmO1Ap5YBSyjPmqy1GrXV1rbUs8bFm1PPBFKwZPh88d6NsPqW3A4c/27rb/2OSN2RwW+y5o/YODWuGzwfP3SibMHNrhs8Hz90om0/pzXWTWVgzfD547kbZfIqzMxgQnVBK+ZU5PW+S5C+Gfzyv1vrYqP1vDNzxswyllNULlN+ewXss/yjJX5ZSDklycwYffnVkks9kcBFo+ack15RSzsnglrNXJ9knydX537+gqbU+Wkp5XZKLknxxzgfIPZTBtPY3MviQr52H2zqnlPKhDCatSfLS4fMfDS+UyeD9mP9j6o2x0ZLNsTg7ySbDvtcmeXoGPb8og/eNv83/UWWpZHM8XDcZN9kcC9dNxk42l6/W+uNSyolJPp3kilLK+Rm8/fKgDFY++24Gr2G/1Q4sLbaxPbK45eWeNfze52dwS9ydGdxCdnUG78Xcffh9q9c59urh9l9I8p+S3JTk4SS3JfnLJFs3etohyQeSXJdB4B7IIPjnJfmPSTab872rsoTl9abweq7ZwGu5atY9emwcD9kc62v5riRfSfKDJP86/Fm/l8G/AO0z6/48Nq6HbI799XTd9BjLQzbH+lq6bnqM7SGbE3lNX5LkC0l+ksEdeN9L8qEk28y6t2k8yvBFAAAAAKBnfMYPAAAAQE8Z/AAAAAD0lMEPAAAAQE8Z/AAAAAD01FSXcy+l+CRpVrRaa5l1D/ORTVY62YRukk3oJtmEbmplc1l3/JRSDiulfLuU8t1SyruXcyxgfGQTukk2oZtkE7pJNmE8Rl7OvZSyaZLvJDk0ydokX09yXK31hgX2MYFlRZvGv47IJiydbEI3ySZ0k2xCN03ijp8XJflurfWWWusjST6d5OhlHA8YD9mEbpJN6CbZhG6STRiT5Qx+dknygzl/Xjvc9hSllBNLKVeVUq5axrmAxZNN6CbZhG6STegm2YQxWc6HO893C9F6t9bVWs9Ickbi1juYEtmEbpJN6CbZhG6STRiT5dzxszbJrnP+/JwkP1xeO8AYyCZ0k2xCN8kmdJNswpgsZ/Dz9SR7lVL2KKU8Lckbk3x+PG0ByyCb0E2yCd0km9BNsgljMvJbvWqtj5VS3pHkoiSbJvlErfX6sXUGjEQ2oZtkE7pJNqGbZBPGZ+Tl3Ec6mfdcssJNY+nLUcgmK51sQjfJJnSTbEI3TWI5dwAAAAA6zOAHAAAAoKcMfgAAAAB6yuAHAAAAoKdGXtULAAAAYFJe9apXNWsXXnhhs3bbbbc1az//8z+/rJ42Ru74AQAAAOgpgx8AAACAnjL4AQAAAOgpgx8AAACAnjL4AQAAAOgpgx8AAACAnrKcOwAAADATW2+9dbN29tlnN2ullGbt7rvvXlZPfeOOHwAAAICeMvgBAAAA6CmDHwAAAICeMvgBAAAA6CmDHwAAAICeMvgBAAAA6CnLuXfYG9/4xmbtjDPOaNae85znzLv9vvvuW3ZPALAxOu2005q1L37xi/Nuv/TSSyfVDgCsKPvtt1+z9rGPfaxZ22677Zq173//+83ab/3Wby2usRXCHT8AAAAAPWXwAwAAANBTBj8AAAAAPWXwAwAAANBTBj8AAAAAPWVVrw77zd/8zWZtyy23bNbOP//8ebcfe+yxzX3uvffeRfcFfbH55ps3a5tsYi6+rkcffbRZe+yxx6bYCSzdQitl/uIv/uK8263qBU/lurk0rpusNL/+67/erJ166qkj7Xfrrbc2a4ceemizdssttzRrK9GyBj+llDVJ7k/yeJLHaq3tNdqAqZFN6CbZhG6STegm2YTxGMcdP4fUWn88huMA4yWb0E2yCd0km9BNsgnL5J5MAAAAgJ5a7uCnJvlyKeXqUsqJ831DKeXEUspVpZSrlnkuYPFkE7pJNqGbZBO6STZhDJb7Vq8Da60/LKXskOQrpZSbaq1P+STEWusZSc5IklJKXeb5gMWRTegm2YRukk3oJtmEMVjWHT+11h8On+9M8tkkLxpHU8DyyCZ0k2xCN8kmdJNswniMfMdPKWWLJJvUWu8ffv2qJO012liySy65pFlbaFnaV7ziFfNu33vvvZv7XHnllYtvjE5bidncf//9m7WTTz65WXvZy17WrG299dbL6qmPvvOd7zRrBx10ULN2xx13TKKdjc5KzObGovV3wc4779zc5/bbb59UO0zZSsym6+Z0uG4uz0rM5sbiyCOPnHf72Wef3dxnq622GulcRx11VLNmyfbFW85bvXZM8tlSypPH+e+11i+NpStgOWQTukk2oZtkE7pJNmFMRh781FpvSbLPGHsBxkA2oZtkE7pJNqGbZBPGx3LuAAAAAD1l8AMAAADQUwY/AAAAAD1l8AMAAADQU8tZ1YsJW7t2bbP2+OOPN2ubbrrpvNsPOeSQ5j6Wc6fr9tmn/dl+F1xwQbO2zTbbTKKdFWnvvfdu1p773Oc2a5alpQtOOumkZu2cc86Zd/sJJ5zQ3Of973//cluCiXLdnD3XTTZmO+ywQ7P2qU99at7tW2yxxUjneu9739us3XjjjSMdk6dyxw8AAABATxn8AAAAAPSUwQ8AAABATxn8AAAAAPSUwQ8AAABATxn8AAAAAPSU5dw77MILL2zW7rnnnmZt++23n3f74Ycf3tzn9NNPb9YeffTRZg3GaZNN2rPoN7/5zc3aQkvPLvT7+w//8A/N2g033NCsXXTRRc3aAw880Ky1HHPMMc3aVVdd1aytXbt2yedKkkMOOaRZ22233Zq1Qw89tFm79dZbR+oFpuULX/hCs/ajH/1o3u0LLef+13/9183agw8+uOi+YDlcN9fnugmL97SnPa1ZO/fcc5u11rLttdbmPieffHKzdtpppzVrTzzxRLPG4rnjBwAAAKCnDH4AAAAAesrgBwAAAKCnDH4AAAAAesrgBwAAAKCnDH4AAAAAeqostOTa2E9WyvRO1nMf+MAHmrU//uM/XvLxtt1222bt3nvvXfLxmF+ttcy6h/l0JZv77rtvs/aNb3xjpGN+/OMfb9ZOPPHEkY5J/8jmyvbhD3943u1/8Ad/0NznV37lV5q166+/ftk9MSCbC3PdZFZksx8uueSSZu2ggw5a8vFOPfXUZm3VqlVLPh5L18qmO34AAAAAesrgBwAAAKCnDH4AAAAAesrgBwAAAKCnDH4AAAAAesrgBwAAAKCnNtvQN5RSPpHkyCR31lpfMNy2bZJzkuyeZE2S19da75lcm6zroYceGuvxXvGKVzRr559//ljPxXj0MZu//Mu/PNJ+999/f7N2+umnj9oOjKSP2ey7n/3sZ7NugSnoYzZdN+mDPmazSxbK9Etf+tKRjnnttdfOu/3MM88c6XhM3mLu+Fmd5LB1tr07ycW11r2SXDz8MzBdqyOb0EWrI5vQRasjm9BFqyObMFEbHPzUWi9Ncvc6m49Octbw67OSHDPetoANkU3oJtmEbpJN6CbZhMkb9TN+dqy13p4kw+cdxtcSsAyyCd0km9BNsgndJJswRhv8jJ/lKqWcmOTESZ8HWBrZhG6STegm2YRukk3YsFHv+LmjlLJzkgyf72x9Y631jFrrfrXW/UY8F7B4sgndJJvQTbIJ3SSbMEajDn4+n+T44dfHJ/nceNoBlkk2oZtkE7pJNqGbZBPGaDHLuX8qycFJti+lrE1ySpIPJDm3lPKWJP8rybGTbJL13XzzzWM93vOf//xmzXLu3dTHbL7gBS8Yab9/+Zd/adZuuummUdsZu2222Wbe7c973vOm3EnbN7/5zWbtwQcfnGInG68+ZpP1tfJMd/Uxm66bs+e6uXx9zOa0HXTQQc3a7/7u7zZrm266abN23XXXNWtHHnnkvNt/8IMfNPdhtjY4+Km1HtcovWLMvQBLIJvQTbIJ3SSb0E2yCZM36lu9AAAAAOg4gx8AAACAnjL4AQAAAOgpgx8AAACAnjL4AQAAAOipDa7qRTd96UtfmnULMHZ77bXXSPvdfPPNY+4k2XPPPZu1o446qlk74IADmrVXvvKV827v0rLQ3//+95u1Cy64oFn76Ec/2qx1aWlgmM+111675H0OPfTQZu2yyy5bTjuwaK6bs+e6ybTssMMOzdqf/dmfNWtPf/rTm7Vaa7N28sknN2utZdv333//5j4veclLmrXXve51zdqo7r///mbtrW99a7N22223jb2XLnDHDwAAAEBPGfwAAAAA9JTBDwAAAEBPGfwAAAAA9JTBDwAAAEBPGfwAAAAA9JTl3IHOWGi514XstNNOzdoznvGMZu1tb3tbs/bud7+7WXv2s5+9uMY2QnvssUezdtJJJzVrb37zm5u1hZbovOiiixbXGEzQJZdcMu/2n/zkJ819tt5660m1A4vmujl7rptMywtf+MJm7cADDxzpmGeccUaztuuuuzZrN9xww7zbn/Oc5zT32XLLLZu1UkqzttCS86O6/PLLm7XjjjuuWbvsssvG3su0uOMHAAAAoKcMfgAAAAB6yuAHAAAAoKcMfgAAAAB6yuAHAAAAoKfKJD4lu3myUqZ3sp7bZpttmrWFViFpOeWUU5q1P/3TP13y8ZhfrbX9kfUz1JVsfvazn23Wjj766GZtob/HHnnkkWZt8803X1xjS/Dnf/7nzVprBYSvf/3rzX3Wrl277J7WdfDBBzdrBxxwQLP2zne+s1nbaqutmrUnnniiWfvVX/3Vebe3XqtJkU3mc9NNNzVrC/2987znPW8S7axIsrkw1831uW5Oh2xO32GHHdasXXDBBSMd88EHH2zWtthii5GOOYqzzjqrWdtzzz2btYX+Lnj5y1/erO2zzz7N2uGHH96sbQyr6rWy6Y4fAAAAgJ4y+AEAAADoKYMfAAAAgJ4y+AEAAADoKYMfAAAAgJ4y+AEAAADoqc1m3QDd8Na3vrVZs5w703LrrbeOtF8p7RVFF1p69vHHH2/WPvjBDzZrCy09u9CymF3xpS99aaTaRz7ykWbt29/+drP27Gc/u1m7+OKL592+xx57NPd5+OGHmzUYpy9/+cvN2hvf+MZmbccdd2zW7rjjjmX1BHO5bk6H6yZdcOCBB479mAst2V5rbdbOPffcebe/733va+7zve99r1l77LHHmrVNNmnfq7LQ30l77713s3bTTTc1a321wTt+SimfKKXcWUq5bs62VaWU20op1wwfR0y2TWBdsgndJJvQTbIJ3SSbMHmLeavX6iSHzbP9I7XWfYePC8bbFrAIqyOb0EWrI5vQRasjm9BFqyObMFEbHPzUWi9NcvcUegGWQDahm2QTukk2oZtkEyZvOR/u/I5SyreGt+Zt0/qmUsqJpZSrSilXLeNcwOLJJnSTbEI3ySZ0k2zCmIw6+PlYkj2T7Jvk9iQfbn1jrfWMWut+tdb9RjwXsHiyCd0km9BNsgndJJswRiMNfmqtd9RaH6+1PpHkvyR50XjbAkYhm9BNsgndJJvQTbIJ4zXScu6llJ1rrbcP//jaJNct9P1035ZbbtmsLbSk5F133TWJdhjRxp7ND3+4+Y85edWrXtWsLbR08le/+tVm7bTTTmvWrrzyymZtpbr33nubtVWrVjVrH/3oR5u11n+7N7zhDc19zjrrrGatqzb2bK5UC/3Ob7/99s3annvu2axZzr1bNvZsum52m+vm6Db2bE7CQw89NNXz/c3f/E2z9nu/93tT62OhJdsXWur9ve997yTa2WhtcPBTSvlUkoOTbF9KWZvklCQHl1L2TVKTrEnytsm1CMxHNqGbZBO6STahm2QTJm+Dg59a63HzbD5zAr0ASyCb0E2yCd0km9BNsgmTt5xVvQAAAADoMIMfAAAAgJ4y+AEAAADoKYMfAAAAgJ4qtdbpnayU6Z2s57bYYotm7Zprrpl3+0LLyy7kuOPm+7y1gXPOOWekY65UtdYy6x7mI5ss1zOf+cxm7brr2iuw7rLLLvNuP//885v7HHvssYtvbJFkk/kcdNBBzdoll1zSrL3//e9v1iwvuzSySV+5bk5Gn7N52GGHNWsXXHDBSMec9u/NuC30/1PPPvvskY55+OGHN2sXXXTRSMecplY23fEDAAAA0FMGPwAAAAA9ZfADAAAA0FMGPwAAAAA9ZfADAAAA0FMGPwAAAAA9tdmsG2A0Dz74YLN2+eWXz7t9oeXcFzreN7/5zcU3BivAFlts0awtlKU+++lPf9qsfeUrX2nWTjjhhHm377333sttCZbtqquuatbWrFnTrG2++eYT6AY2Xq6b63PdpAu6kr+dd965WfulX/qlZu1973vfSOe75JJLmrWrr756pGN2nTt+AAAAAHrK4AcAAACgpwx+AAAAAHrK4AcAAACgpwx+AAAAAHrK4AcAAACgpyznTpLkoYceatZuuummKXYC3fCmN72pWXvLW97SrL361a9u1h5++OFl9dRlO+64Y7N25JFHLvl4d95553LagbFYaJnbL37xi83aQn9/nHbaac3aXXfdtbjGoINcN5fGdZMu+O3f/u1m7fnPf/6Sj/eZz3ymWdt///2btX322adZ23333ZfcR5JceumlzdrrX//6Zu0nP/nJSOfrOnf8AAAAAPSUwQ8AAABATxn8AAAAAPSUwQ8AAABATxn8AAAAAPSUwQ8AAABAT21wOfdSyq5JPplkpyRPJDmj1vpXpZRtk5yTZPcka5K8vtZ6z+RaZZK23XbbZu0P//APm7UPfehDk2iHRZDN5Xv605/erJ1yyinN2n333desPf7448vqadZ22mmnZu34449v1t7+9rc3a9tvv32z9tOf/nTe7atWrWru03WyuTIstPT6Qr/zu+2220jHZPlkc/lcN9fnurl8srk4Cy1Pfs455zRrb3jDG5q1Ukqztt9++y2usWXusxx/+7d/26y95z3vadZaOeqzxdzx81iS/1RrfV6SFyc5qZTy/CTvTnJxrXWvJBcP/wxMj2xCN8kmdJNsQjfJJkzYBgc/tdbba63fGH59f5Ibk+yS5OgkZw2/7awkx0yoR2AesgndJJvQTbIJ3SSbMHkbfKvXXKWU3ZP8WpIrkuxYa709GYS1lLJDY58Tk5y4zD6BBcgmdJNsQjfJJnSTbMJkLHrwU0rZMsn5Sd5Za71vofcDzlVrPSPJGcNj1FGaBNpkE7pJNqGbZBO6STZhcha1qlcp5ecyCOHZtdbPDDffUUrZeVjfOcmdk2kRaJFN6CbZhG6STegm2YTJ2uDgpwxGrWcmubHWevqc0ueTPPlR9ccn+dz42wNaZBO6STahm2QTukk2YfJKrQvfDVdKeWmSf0xybQbL6yXJn2Twvstzk/x8kv+V5Nha690bOJZb76bgxS9+8bzb//mf/3mk41144YXN2mte85qRjrlS1VoXd8/qIsjm8m233XbN2vXXX9+s7bDDvG8xT5L8/d//fbP26U9/et7tt956a3OfUW2++ebN2hFHHNGsve51r2vW9thjj5F6WWjJzKOOOmre7ZdddtlI5xqVbLJUb3rTm5q1s846q1k79thjm7XzzjtvWT31kWx2i+vm+lw3l082l2/fffdt1r72ta81a1tttdUEulm6j3/8483aqaee2qzddtttzdqG5hx91crmBj/jp9Z6WZJWsF+xnKaA0ckmdJNsQjfJJnSTbMLkLeozfgAAAADY+Bj8AAAAAPSUwQ8AAABATxn8AAAAAPSUwQ8AAABAT21wOfexnmyFLq83bdtss8282y+//PLmPnvttVezdtxxxzVr55xzzuIbY6xLX46TbK7v7LPPbtYWysRK9U//9E/N2vHHH9+s3XLLLZNoZ8lkk6Xacsstm7VrrrmmWbvzzjubtZe85CXLaamXZHPj4bq5NK6bkyGbrHStbLrjBwAAAKCnDH4AAAAAesrgBwAAAKCnDH4AAAAAesrgBwAAAKCnDH4AAAAAemqzWTfA+N1zzz3zbr/33nub+/zrv/5rs3bzzTcvtyXY6PzO7/xOs/Z3f/d3zdq73vWuZm3//fdfch+ltFdLrXW0FUsXWkL2iiuuaNbOO++8Zu3KK69s1p544onFNQYbkQceeKBZO/PMM5u1I444YhLtwMy5bq7PdRPoCnf8AAAAAPSUwQ8AAABATxn8AAAAAPSUwQ8AAABATxn8AAAAAPRUGfXT7Uc6WSnTOxl0UK21vdTEDMnm+GyySXue/rSnPW2KnbQ98sgjzdpKXUlENqGbZLP/XDc3TrIJ3dTKpjt+AAAAAHrK4AcAAACgpwx+AAAAAHrK4AcAAACgpwx+AAAAAHrK4AcAAACgpza4nHspZdckn0yyU5InkpxRa/2rUsqqJG9NctfwW/+k1nrBBo5leT1WtHEufSmbMD6yCd0km9BNsgnd1MrmYgY/OyfZudb6jVLKVkmuTnJMktcneaDW+qHFNiGIrHRjvkjKJoyJbEI3ySZ0k2xCN7Wyudkidrw9ye3Dr+8vpdyYZJfxtgcslWxCN8kmdJNsQjfJJkzekj7jp5Sye5JfS3LFcNM7SinfKqV8opSyzbibAxZHNqGbZBO6STahm2QTJmPRg59SypZJzk/yzlrrfUk+lmTPJPtmMKH9cGO/E0spV5VSrlp+u8C6ZBO6STahm2QTukk2YXI2+Bk/SVJK+bkkX0hyUa319Hnquyf5Qq31BRs4jvdcsqKN8/3QiWzCuMgmdJNsQjfJJnRTK5sbvOOnlFKSnJnkxrkhHH4I15Nem+S65TYJLJ5sQjfJJnSTbEI3ySZM3mJW9Xppkn9Mcm0Gy+slyZ8kOS6D2+5qkjVJ3jb8YK6FjmUCy4o25hUQZBPGRDahm2QTukk2oZtGXs59nASRlW7ct8WOi2yy0skmdJNsQjfJJnTTyG/1AgAAAGDjZPADAAAA0FMGPwAAAAA9ZfADAAAA0FMGPwAAAAA9ZfADAAAA0FMGPwAAAAA9ZfADAAAA0FMGPwAAAAA9ZfADAAAA0FMGPwAAAAA9ZfADAAAA0FObTfl8P05y6/Dr7Yd/7oKu9KKP9XWll3H0sds4GpkQ2VyYPtbXlV5kcza60os+1teVXmRz+rrSR9KdXrrSR9KdXmRz+rrSR9KdXvSxvolms9Ral3ns0ZRSrqq17jeTk6+jK73oY31d6aUrfUxDl37WrvSij/V1pZeu9DENXfpZu9KLPtbXlV660sc0dOVn7UofSXd66UofSXd66Uof09CVn7UrfSTd6UUf65t0L97qBQAAANBTBj8AAAAAPTXLwc8ZMzz3urrSiz7W15VeutLHNHTpZ+1KL/pYX1d66Uof09Cln7UrvehjfV3ppSt9TENXftau9JF0p5eu9JF0p5eu9DENXflZu9JH0p1e9LG+ifYys8/4AQAAAGCyvNULAAAAoKcMfgAAAAB6aiaDn1LKYaWUb5dSvltKefcsehj2saaUcm0p5ZpSylVTPvcnSil3llKum7Nt21LKV0opNw+ft5lRH6tKKbcNX5drSilHTKGPXUspl5RSbiylXF9K+f3h9lm8Jq1epv66TJtsyuY8fXQimys5l4lsDs8tm0/tQzY7QDZlc54+ZHPGupLLYS8zyWZXcrlAL7I55WxO/TN+SimbJvlOkkOTrE3y9STH1VpvmGojg17WJNmv1vrjGZz73yV5IMkna60vGG77iyR311o/MPxLapta67tm0MeqJA/UWj80yXOv08fOSXautX6jlLJVkquTHJPkhEz/NWn18vpM+XWZJtn8t3PL5lP76EQ2V2ouE9mcc27ZfGofsjljsvlv55bNp/YhmzPUpVwO+1mTGWSzK7lcoJdVkc2pZnMWd/y8KMl3a6231FofSfLpJEfPoI+ZqrVemuTudTYfneSs4ddnZfALMIs+pq7Wenut9RvDr+9PcmOSXTKb16TVS9/JZmRznj46kc0VnMtENpPI5jx9yObsyWZkc54+ZHO25DLdyeUCvUzdSs/mLAY/uyT5wZw/r83s/hKqSb5cSrm6lHLijHqYa8da6+3J4BciyQ4z7OUdpZRvDW/Nm8ptgE8qpeye5NeSXJEZvybr9JLM8HWZAtlsk810J5srLJeJbC5ENiObMySbbbIZ2ZyRLuUy6VY2u5TLRDanms1ZDH7KPNtmtab8gbXWFyY5PMlJw9vQSD6WZM8k+ya5PcmHp3XiUsqWSc5P8s5a633TOu8ie5nZ6zIlstl9Kz6bKzCXiWxuDGRTNp8km90imysvm13KZSKbLbI55WzOYvCzNsmuc/78nCQ/nEEfqbX+cPh8Z5LPZnBr4CzdMXzP35Pv/btzFk3UWu+otT5ea30iyX/JlF6XUsrPZfDLf3at9TPDzTN5TebrZVavyxTJZptsdiCbKzSXiWwuRDZlc5Zks002ZXNWOpPLpHPZ7EQuE9mcRTZnMfj5epK9Sil7lFKeluSNST4/7SZKKVsMP0wppZQtkrwqyXUL7zVxn09y/PDr45N8bhZNPPmLP/TaTOF1KaWUJGcmubHWevqc0tRfk1Yvs3hdpkw222RzxtlcwblMZHMhsimbsySbbbIpm7PSiVwmncxmJ3KZyOZ8fUz8Nam1Tv2R5IgMPm39e0neO6MefiHJN4eP66fdR5JPZXAL16MZTKbfkmS7JBcnuXn4vO2M+vhvSa5N8q0MgrDzFPp4aQa3YX4ryTXDxxEzek1avUz9dZn2QzZlc54+OpHNlZzL4c8vm7K5bh+y2YGHbMrmPH3I5owfXcjlsI+ZZbMruVygF9mccjanvpw7AAAAANMxi7d6AQAAADAFBj8AAAAAPWXwAwAAANBTBj8AAAAAPWXwAwAAANBTBj8AAAAAPWXwAwAAANBT/z8zWrjGQpujgwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i, idx in enumerate(np.random.choice(X_train.shape[0], 5)):\n",
    "    ax[i].imshow(X_train[idx], cmap='gray', vmin=0, vmax=255)\n",
    "    ax[i].set_title(f'Label = {y_train[idx]}', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1175ca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Run this cell only once. If you have to rerun it multiple times, \n",
    "# make sure that you run it after rerunning the previous 2 cells.\n",
    "\n",
    "# Normalize dataset: pixel values lie between 0 and 255\n",
    "# Normalize them so the pixelwise mean is zero and standard deviation is 1\n",
    "\n",
    "X_train = X_train.float()  # convert to float32\n",
    "# NOTE: we are returning a single mean/std over all the pixels, rather than a pixel-wise one\n",
    "mean, std = X_train.mean(), X_train.std()  \n",
    "X_train = (X_train - mean) / (std + 1e-6)  # avoid divide by zero\n",
    "# X_train /= torch.norm(X_train, dim=(1, 2)).max()\n",
    "\n",
    "X_test = X_test.float()\n",
    "X_test = (X_test - mean) / (std + 1e-6)\n",
    "# X_test /= torch.norm(X_test, dim=(1, 2)).max()\n",
    "\n",
    "n_class = np.unique(y_train).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902b025d",
   "metadata": {},
   "source": [
    "### Create convolutional autoencoder\n",
    "Use the same convolutional autoencoder as in this weekâ€™s lab, with a lower latent dimension of 40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "306125dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderModule(torch.nn.Module):\n",
    "    def __init__(self, lower_dimension):\n",
    "        super().__init__()\n",
    "        # (B, 1, 28, 28) -> (B, 4, 12, 12)\n",
    "        self.conv1 = torch.nn.Conv2d(1, 4, kernel_size=5, stride=2, padding=0) \n",
    "        self.conv2 = torch.nn.Conv2d(4, 8, kernel_size=3, stride=2, padding=0)\n",
    "        # Flatten (B, 8, 5, 5) -> (B, 8*5*5): do this in `forward()`\n",
    "        # (B, 8*5*5) -> (B, lower_dimension); 8*5*5 = 200\n",
    "        self.linear = torch.nn.Linear(200, lower_dimension)\n",
    "    \n",
    "    def forward(self, images):\n",
    "        out = relu(self.conv1(images))  # conv1 + relu\n",
    "        out = relu(self.conv2(out))  # conv2 + relu\n",
    "        out = out.view(out.shape[0], -1)  # flatten\n",
    "        out = self.linear(out)  # Linear\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38bb3d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderModule(torch.nn.Module):\n",
    "    def __init__(self, lower_dimension):\n",
    "        super().__init__()\n",
    "        # (B, lower_dimension) -> (B, linear)\n",
    "        self.linear_t = torch.nn.Linear(lower_dimension, 200)\n",
    "        # Unflatten (B, 8*5*5) -> (B, 8, 5, 5); do this in `forward()`\n",
    "        # (B, 8, 5, 5) -> (B, 4, 12, 12)\n",
    "        self.conv2_t = torch.nn.ConvTranspose2d(8, 4, kernel_size=3, stride=2, padding=0, output_padding=1)\n",
    "        # (B, 4, 12, 12) -> (B, 1, 28, 28)\n",
    "        self.conv1_t = torch.nn.ConvTranspose2d(4, 1, kernel_size=5, stride=2, padding=0, output_padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply in reverse order\n",
    "        out = relu(self.linear_t(x))  # linear_t + relu\n",
    "        out = out.view(out.shape[0], 8, 5, 5)  # Unflatten\n",
    "        out = relu(self.conv2_t(out))  # conv2_t + relu\n",
    "        out = self.conv1_t(out)  # conv1_t (note: no relu at the end)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89cd3e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(torch.nn.Module):\n",
    "    def __init__(self, lower_dimension):\n",
    "        super().__init__()\n",
    "        self.encoder = EncoderModule(lower_dimension)\n",
    "        self.decoder = DecoderModule(lower_dimension)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        # Pass the images through the encoder to get the representations.\n",
    "        # Then, pass the representations through the decoder to get the reconstructed images\n",
    "        # images -> encoder(.) -> decoder(.)\n",
    "        out = self.encoder(images)\n",
    "        out = self.decoder(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    def encode_images(self, images):\n",
    "        return self.encoder(images)\n",
    "    \n",
    "    def decode_representations(self, representations):\n",
    "        return self.decoder(representations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd2ef3",
   "metadata": {},
   "source": [
    "### Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42c08d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(true_images, reconstructed_images):  # square loss\n",
    "    residual = (true_images - reconstructed_images).view(-1)  # flatten into a vector\n",
    "    # return the average over examples\n",
    "    return 0.5 * torch.norm(residual) ** 2 / (true_images.shape[0])\n",
    "\n",
    "def compute_objective(model, images):\n",
    "    # reshape images from (B, 28, 28) -> (B, 1, 28, 28) as required by the model\n",
    "    images = images.unsqueeze(1)  # Add channel dimension\n",
    "    reconstructed_images = model(images)\n",
    "    return loss_function(images, reconstructed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "487a7e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_logs(model, verbose=False): # Only report loss\n",
    "    train_loss = compute_objective(model, X_train)\n",
    "    test_loss = compute_objective(model, X_test)\n",
    "    if verbose:\n",
    "        print('Train Loss = {:.3f}, Test Loss = {:.3f}, '.format(\n",
    "                train_loss.item(), test_loss.item(),\n",
    "    ))\n",
    "    return (train_loss, test_loss)\n",
    "\n",
    "def minibatch_sgd_one_pass(model, X, learning_rate, batch_size, verbose=False):\n",
    "    num_examples = X.shape[0]\n",
    "    average_loss = 0.0\n",
    "    num_updates = int(round(num_examples / batch_size))\n",
    "    for i in range(num_updates):\n",
    "        idxs = np.random.choice(num_examples, size=(batch_size,)) \n",
    "        # compute the objective. \n",
    "        objective = compute_objective(model, X[idxs]) \n",
    "        average_loss = 0.99 * average_loss + 0.01 * objective.item()\n",
    "        if verbose and (i+1) % 100 == 0:\n",
    "            print(\"{:.3f}\".format(average_loss))\n",
    "        \n",
    "        # Exercise:\n",
    "        # compute the gradient using automatic differentiation\n",
    "        gradients = torch.autograd.grad(outputs=objective, inputs=model.parameters())\n",
    "\n",
    "        # Perform the SGD update\n",
    "        with torch.no_grad():\n",
    "            for (w, g) in zip(model.parameters(), gradients):\n",
    "                w -= learning_rate * g\n",
    "                \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b46425b",
   "metadata": {},
   "source": [
    "### Corruption function\n",
    "As the corruption function $C(Â·)$, we zero out a randomly chosen 14 Ã— 14 patch in the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dc1428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_image_batch(images):\n",
    "    # Add a 14x14 square of zeros in a 28x28 image\n",
    "    # images: (B, 1, 28, 28)\n",
    "    \n",
    "    patch_size = 14  # zero out a 14x14 patch\n",
    "    batch_size = images.shape[0]\n",
    "    height, width = images.shape[-2:]  # height and width of each image\n",
    "\n",
    "    starting_h = np.random.choice(height - patch_size, size=batch_size, replace=True)\n",
    "    starting_w = np.random.choice(width - patch_size, size=batch_size, replace=True)\n",
    "\n",
    "    images_corrupted = images.clone()  # corrupt a copy so we do not lose the originals\n",
    "    for b in range(batch_size):\n",
    "        h = starting_h[b]\n",
    "        w = starting_w[b]\n",
    "        images_corrupted[b, 0, h:h+patch_size, b:b+patch_size] = 0  # set to 0\n",
    "    return images_corrupted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ea54e9",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "Train the model for 40 epochs starting with $\\gamma_0 = 2.5 \\cdot 10^{-4}$ and $t_0 = 10$ (i.e., halve the learning rate every 10 epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d6f09b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, LR: 0.00025, Train Loss = 393.826, Test Loss = 401.827, \n",
      "Iteration 1, LR: 0.00025, Train Loss = 80.866, Test Loss = 80.153, \n",
      "Iteration 2, LR: 0.00025, Train Loss = 81.095, Test Loss = 80.308, \n",
      "Iteration 3, LR: 0.00025, Train Loss = 55.325, Test Loss = 55.098, \n",
      "Iteration 4, LR: 0.00025, Train Loss = 51.002, Test Loss = 50.783, \n",
      "Iteration 5, LR: 0.00025, Train Loss = 47.594, Test Loss = 47.473, \n",
      "Iteration 6, LR: 0.00025, Train Loss = 48.233, Test Loss = 48.165, \n",
      "Iteration 7, LR: 0.00025, Train Loss = 44.607, Test Loss = 44.617, \n",
      "Iteration 8, LR: 0.00025, Train Loss = 45.306, Test Loss = 45.434, \n",
      "Iteration 9, LR: 0.00025, Train Loss = 43.987, Test Loss = 43.958, \n",
      "Iteration 10, LR: 0.000125, Train Loss = 40.120, Test Loss = 40.277, \n",
      "Iteration 11, LR: 0.000125, Train Loss = 40.249, Test Loss = 40.333, \n",
      "Iteration 12, LR: 0.000125, Train Loss = 39.366, Test Loss = 39.520, \n",
      "Iteration 13, LR: 0.000125, Train Loss = 39.841, Test Loss = 40.075, \n",
      "Iteration 14, LR: 0.000125, Train Loss = 39.342, Test Loss = 39.548, \n",
      "Iteration 15, LR: 0.000125, Train Loss = 39.417, Test Loss = 39.587, \n",
      "Iteration 16, LR: 0.000125, Train Loss = 39.174, Test Loss = 39.445, \n",
      "Iteration 17, LR: 0.000125, Train Loss = 39.014, Test Loss = 39.254, \n",
      "Iteration 18, LR: 0.000125, Train Loss = 38.711, Test Loss = 38.978, \n",
      "Iteration 19, LR: 0.000125, Train Loss = 39.031, Test Loss = 39.272, \n",
      "Iteration 20, LR: 6.25e-05, Train Loss = 38.046, Test Loss = 38.316, \n",
      "Iteration 21, LR: 6.25e-05, Train Loss = 37.755, Test Loss = 38.067, \n",
      "Iteration 22, LR: 6.25e-05, Train Loss = 37.795, Test Loss = 38.126, \n",
      "Iteration 23, LR: 6.25e-05, Train Loss = 37.838, Test Loss = 38.145, \n",
      "Iteration 24, LR: 6.25e-05, Train Loss = 37.661, Test Loss = 38.017, \n",
      "Iteration 25, LR: 6.25e-05, Train Loss = 37.771, Test Loss = 38.117, \n",
      "Iteration 26, LR: 6.25e-05, Train Loss = 37.766, Test Loss = 38.135, \n",
      "Iteration 27, LR: 6.25e-05, Train Loss = 37.480, Test Loss = 37.824, \n",
      "Iteration 28, LR: 6.25e-05, Train Loss = 37.532, Test Loss = 37.887, \n",
      "Iteration 29, LR: 6.25e-05, Train Loss = 37.479, Test Loss = 37.898, \n",
      "Iteration 30, LR: 3.125e-05, Train Loss = 37.122, Test Loss = 37.503, \n",
      "Iteration 31, LR: 3.125e-05, Train Loss = 37.019, Test Loss = 37.405, \n",
      "Iteration 32, LR: 3.125e-05, Train Loss = 37.021, Test Loss = 37.403, \n",
      "Iteration 33, LR: 3.125e-05, Train Loss = 36.893, Test Loss = 37.267, \n",
      "Iteration 34, LR: 3.125e-05, Train Loss = 36.983, Test Loss = 37.336, \n",
      "Iteration 35, LR: 3.125e-05, Train Loss = 36.926, Test Loss = 37.306, \n",
      "Iteration 36, LR: 3.125e-05, Train Loss = 36.884, Test Loss = 37.308, \n",
      "Iteration 37, LR: 3.125e-05, Train Loss = 36.821, Test Loss = 37.227, \n",
      "Iteration 38, LR: 3.125e-05, Train Loss = 36.956, Test Loss = 37.366, \n",
      "Iteration 39, LR: 3.125e-05, Train Loss = 36.831, Test Loss = 37.244, \n",
      "Iteration 40, LR: 1.5625e-05, Train Loss = 36.650, Test Loss = 37.071, \n"
     ]
    }
   ],
   "source": [
    "initial_learning_rate = 2.5e-4\n",
    "learning_rate_threshold = 10\n",
    "batch_size = 1\n",
    "lower_dimension = 40 # use a lower dimensionality of 40\n",
    "num_epochs = 40\n",
    "\n",
    "logs = []\n",
    "\n",
    "model = AutoEncoder(lower_dimension)\n",
    "print(f'Iteration 0, LR: {initial_learning_rate}', end=', ')\n",
    "logs.append(compute_logs(model, verbose=True))\n",
    "\n",
    "for j in range(num_epochs):\n",
    "    # step decay learning rate schedule\n",
    "    num_epoch = j + 1\n",
    "    learning_rate = initial_learning_rate / ( math.pow(2, math.floor(num_epoch/learning_rate_threshold)) )\n",
    "    \n",
    "    model = minibatch_sgd_one_pass(model, X_train, learning_rate, batch_size=batch_size, verbose=False)\n",
    "    print(f'Iteration {num_epoch}, LR: {learning_rate}', end=', ')\n",
    "    logs.append(compute_logs(model, verbose=True))\n",
    "\n",
    "with open('./models/logs.pkl', 'wb') as f:\n",
    "    pickle.dump(logs, f)\n",
    "\n",
    "# save the model parms\n",
    "torch.save(model.state_dict(), f'./models/parms.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672a645a",
   "metadata": {},
   "source": [
    "### Model Output\n",
    "Show some examples of the denoising process from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b785b924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
