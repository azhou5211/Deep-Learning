{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1> Lecture 6: Embeddings and ML Experiments </h1> </center>\n",
    "<center> Krishna Pillutla, Zaid Harchaoui </center>\n",
    "    <center> Data 598 (Winter 2022), University of Washington </center>\n",
    "\n",
    "We will discuss two topics this lecture:\n",
    "- Embeddings for natural language\n",
    "- Model Selection with statistical tests\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Embeddings for Natural Language\n",
    "\n",
    "The field of **natural language processing (NLP)** is concerned with the interaction between computers and natural (human) language. This involves \"understanding\" the contents of documents, including the contextual nuances of the language within them. \n",
    "\n",
    "**Embeddings**:\n",
    "The use of machine learning for NLP, both in the classical settings as well as the modern deep learning era, have relied on *embedding* words in vector spaces.\n",
    "Words are made of characters, which are combinatorial in nature with no \"neighborhood\" structure which one expects of vectors in, say, a Euclidean space. \n",
    "The magic of embeddings is that they are able to capture some \"neighborhood\" structure in words, e.g., the embedding of synonyms are closer together than of words which have nothing in common. \n",
    "\n",
    "![](https://miro.medium.com/max/2400/1*OEmWDt4eztOcm5pr2QbxfA.png)\n",
    "Image credits: https://towardsdatascience.com/creating-word-embeddings-coding-the-word2vec-algorithm-in-python-using-deep-learning-b337d0ba17a8\n",
    "\n",
    "**Note**: Sometimes, we will work at the level of subword units, rather than words. Mathematically, the same treatment holds irrespective of how we *tokenize* the text. We will refer to these units as *tokens*.\n",
    "\n",
    "\n",
    "**Types of embeddings**:\n",
    "\n",
    "- Global (context-free) embeddings: word2vec, GloVe\n",
    "- Contextual embeddings: ELMo, BERT, ...\n",
    "\n",
    "![](http://ai.stanford.edu/blog/assets/img/posts/2020-03-24-contextual/contextual_mouse_transparent_2.png)\n",
    "Image credit: http://ai.stanford.edu/blog/contextual/\n",
    "\n",
    "\n",
    "**The history of word embeddings**:\n",
    "The research started with global (context-free) embeddings with \n",
    "later research producing contextual embeddings using deep learning.\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\text{word2vec}   &  \\text{GloVe}   &   \\text{ELMo}     &       \\text{BERT}  \\\\\n",
    "2013       &  2014    &   2017     &       2018 \n",
    "\\end{matrix} \n",
    "$$\n",
    "\n",
    "**Playing with embeddings**:\n",
    "For the moment, we postpone a discussion of how the embeddings are constructed. We will play with BERT embeddings, a form of contextual embeddings, using the `transformers` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the transformers library\n",
    "# Important: make sure pip is installed in your conda environment\n",
    "# Run \"pip install transformers\" in your terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c8c9b60fd54e58990cb3ff0fbfe9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4e3100f385426c87a79f652e269bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729072d1c38d4c938ddc2e550f5fc8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "# Download the pre-trained model + tokenizer (a total of 440 MB)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name) # to tokenize the text\n",
    "model = BertModel.from_pretrained(model_name)  # PyTorch module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: tensor([[ 101, 1045, 5067, 2026, 3477, 5403, 3600, 2012, 1996, 2924,  102]])\n",
      "Sentence 2: tensor([[ 101, 3113, 2033, 4826, 2012, 1996, 2314, 2924,  102]])\n",
      "Sentence 1 Length: torch.Size([1, 11])\n",
      "Sentence 2 Length: torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "# Consider these two sentences\n",
    "\n",
    "sentence1 = \"I collected my paycheck at the bank\"\n",
    "sentence2 = \"Meet me tomorrow at the river bank\"\n",
    "\n",
    "# Let us tokenize them \n",
    "tokens_for_sentence1 = tokenizer.encode(sentence1, return_tensors='pt')\n",
    "tokens_for_sentence2 = tokenizer.encode(sentence2, return_tensors='pt')\n",
    "\n",
    "print('Sentence 1:', tokens_for_sentence1)\n",
    "print('Sentence 2:', tokens_for_sentence2)\n",
    "\n",
    "print('Sentence 1 Length:', tokens_for_sentence1.shape)\n",
    "print('Sentence 2 Length:', tokens_for_sentence2.shape)\n",
    "# the leading 1 is the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The token \"102\" corresponds to the word \"bank\".\n",
    "Observe now that the contextual embedding of the word \"bank\" for each case is different. \n",
    "This would not have been the case for a global embedding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11, 768])\n",
      "torch.Size([1, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "outputs1 = model(tokens_for_sentence1,\n",
    "                return_dict=True)\n",
    "\n",
    "# Extract contextual embedding for each token\n",
    "embeddings_for_sentence1 = outputs1.last_hidden_state\n",
    "print(embeddings_for_sentence1.shape) # [batch_size, num_tokens, dimension]\n",
    "\n",
    "outputs2 = model(tokens_for_sentence2,\n",
    "                return_dict=True)\n",
    "\n",
    "# Extract contextual embedding for each token\n",
    "embeddings_for_sentence2 = outputs2.last_hidden_state\n",
    "print(embeddings_for_sentence2.shape) # [batch_size, num_tokens, dimension]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 distance between the embeddings: 5.314887523651123\n"
     ]
    }
   ],
   "source": [
    "embedding_for_bank_1 = embeddings_for_sentence1[0, -1, :]\n",
    "embedding_for_bank_2 = embeddings_for_sentence2[0, -1, :]\n",
    "print('L2 distance between the embeddings:', \n",
    "      torch.norm(embedding_for_bank_1-embedding_for_bank_2).item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis using Embeddings\n",
    "\n",
    "We will look at the standard NLP task of sentiment analysis. \n",
    "Given a piece of text, the goal is to classify it as \"positive\" or \"negative\" in sentiment.\n",
    "\n",
    "![](https://cdn.socialbakers.com/www/storage/www/articles/content/2018-12/1545313838-sentiment-analysis.jpg)\n",
    "Image credits: https://www.socialbakers.com/blog/social-media-sentiment-analysis\n",
    "\n",
    "Our procedure is as follows:\n",
    "- We will use a labeled dataset and cast this as a multiclass classification problem\n",
    "- We will use these BERT embeddings to construct obtain one vector per token. We will simply take the mean of this vector as the feature representation of the entire piece of text.\n",
    "- We will train a simple linear model to predict the output label from these features.\n",
    "\n",
    "\n",
    "Download the data from [here](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data?select=train.tsv.zip).\n",
    "\n",
    "We will use movie reviews from Rotten Tomatoes. The sentiment labels are:\n",
    "- 0 - negative\n",
    "- 1 - somewhat negative\n",
    "- 2 - neutral\n",
    "- 3 - somewhat positive\n",
    "- 4 - positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8529, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SentenceId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Phrase  Sentiment\n",
       "SentenceId                                                              \n",
       "1           A series of escapades demonstrating the adage ...          1\n",
       "2           This quiet , introspective and entertaining in...          4\n",
       "3           Even fans of Ismail Merchant 's work , I suspe...          1\n",
       "4           A positively thrilling combination of ethnogra...          3"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filename = './data/sentiment-analysis-train.tsv'\n",
    "# keep one example per sentence (original data labels each phrase)\n",
    "data = pd.read_csv(filename, sep='\\t').groupby('SentenceId').first()\n",
    "data = data.drop(columns=['PhraseId'])\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Even fans of Ismail Merchant 's work , I suspect , would have a hard time sitting through this one .\""
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.at[3, 'Phrase']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split and featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2) (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "data = data.sample(frac=1)  # shuffle\n",
    "train_data = data[:1000]\n",
    "test_data = data[5000:6000]\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "@torch.no_grad()\n",
    "def featurize(x): # x is pd.Series with text\n",
    "    features = []\n",
    "    for sen in tqdm(x):\n",
    "        sen = tokenizer.encode(sen, return_tensors='pt')\n",
    "        outputs = model(sen, return_dict=True)\n",
    "        embeddings = outputs.last_hidden_state.squeeze() # (len, dim)\n",
    "        mean_embedding = embeddings.mean(axis=0)\n",
    "        features.append(mean_embedding.numpy())\n",
    "    return np.stack(features)  # (n, dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e18be98dc374bf882becb4ada9fda25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3588a0d0ccd34b58a5f153ce1effe026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Takes a few minutes to run\n",
    "x_train = featurize(train_data['Phrase'])\n",
    "y_train = train_data['Sentiment'].values\n",
    "\n",
    "x_test = featurize(test_data['Phrase'])\n",
    "y_test = test_data['Sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xt1 = x_train\n",
    "# xt2 = x_test\n",
    "x_train = xt1\n",
    "x_test = xt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a simple logistic regression classifier to test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.99, random_state=1).fit(x_train)  # keep 99% of the explained variance\n",
    "x_train = pca.transform(x_train)\n",
    "x_test = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.546\n",
      "Test accuracy: 0.418\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, C=0.01).fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(x_train)\n",
    "y_test_pred = clf.predict(x_test)\n",
    "\n",
    "print('Train accuracy:', (y_train_pred == y_train).mean())\n",
    "print('Test accuracy:', (y_test_pred == y_test).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Statistical Tests for Analysis for ML Experiments\n",
    "\n",
    "In some particular safety-critical applications, it might be necessary to make guarantees of the form \n",
    "\"*The misclassification error of my classifier is at most 12% on data from the same distribution as our training data*\". Think of self-driving cars, for instance. The 12% above is an arbitrary number.\n",
    "\n",
    "In these cases, we run hypothesis tests to formalize our claims.\n",
    "\n",
    "**Hypothesis Testing Review**: \n",
    "Suppose we want to show that herbal tea helps with migraines. \n",
    "In the spirit of \"proof by contradiction\", \n",
    "we assume the opposite to be true and say that herbal tea does not help with migraines. \n",
    "If the data looks too \"anomalous\" under this assumption, we arrive at a \n",
    "\"contradiction\", which means that the data is not consistent the \n",
    "claim that \"herbal tea does not help with migraines\" (the opposite of what we set out to show).\n",
    "\n",
    "\n",
    "We have two hypotheses, the null hypothesis (denoted $H_0$; the opposite of what we want to show) and the alternate hypothesis (denoted $H_1$ or $H_a$; what we want to show). \n",
    "From looking at the data, we take one of two steps:\n",
    "- reject the null hypothesis\n",
    "- \"fail\" to reject the null hypothesis\n",
    "\n",
    "\n",
    "**Illustration**: ([credit](https://study.com/cimages/multimages/16/ea0e233d-7bc3-4ba6-a79c-5d8281295985_t_tests.png)): \n",
    "\n",
    "Suppose we are given two distributions with means $\\mu_1$ and $\\mu_2$ respectively. \n",
    "We plot as test statistic (TS) the difference $\\hat\\mu_{1, n} - \\hat\\mu_{2, n}$ between the sample means. The bell-curve is centered at $0$.\n",
    "![](https://study.com/cimages/multimages/16/ea0e233d-7bc3-4ba6-a79c-5d8281295985_t_tests.png)\n",
    "\n",
    "\n",
    "Letting \"acc$(h)$\" denote the classification accuracy of our classification algorithm $h$, We may write this test as the following:\n",
    "$$\n",
    "H_0: \\quad \\text{acc}(h) \\le a_0 \\\\\n",
    "H_1: \\quad \\text{acc}(h) > a_0 ,\n",
    "$$\n",
    "where $a_0$ is some pre-specified accuracy.\n",
    "\n",
    "The outcomes are:\n",
    "- Reject the null: If our data is convincing enough (i.e., the accuracy on our validation set is significantly larger than $a_0$), we reject the null with a certain level of confidence\n",
    "- Fail to reject the null: If the validation accuracy is close to or smaller than $a_0$, we say that we do not have strong enough evidence to reject the null (default) hypothesis. \n",
    "\n",
    "**The $t$-Test to Assess Classification**:\n",
    "\n",
    "Suppose we $K$ training-validation pairs. For each one, we record the \n",
    "validation accuracies $A_1, \\cdots, A_K$. \n",
    "The empirical mean and variance are:\n",
    "$$\n",
    "    m = \\frac{1}{K} \\sum_{k=1}^K A_k\\,, \\quad S^2 = \\frac{1}{K-1}(A_k - m)^2 \\,.\n",
    "$$\n",
    "The test statistic is then\n",
    "$$\n",
    "    T_K := \\frac{\\sqrt{K}(m - a_0)}{S} .\n",
    "$$\n",
    "Under the assumption of independence of each of the training-validation set pairs, \n",
    "it turns out that $T_K$ is distributed according to the Student $t$ distribution with $K-1$ degrees of freedom. \n",
    "\n",
    "In this case, we reject the null with a level of significance $\\alpha$ if \n",
    "$$\n",
    "    T_K > t_{K-1, \\alpha},\n",
    "$$\n",
    "the $(1-\\alpha)$-quantile of of the $t_{K-1}$ distribution. \n",
    "\n",
    "That is, we reject the null if \n",
    "$$\n",
    "    m > a_0 + \\frac{S}{\\sqrt{K}} t_{K-1, \\alpha} \\,.\n",
    "$$\n",
    "Observe what happens as $K$ grows or $\\alpha$ becomes smaller. \n",
    "![](https://lh3.googleusercontent.com/proxy/Rk0TX6KUcZLaFgMU42Qr553ALEHXt1YRIoZRIZfaoTMp69H5UcESVWmj3C-qE1NgtSUyngFqUx-v_O9__tzq29yUeZ3OKcmwVbby2bJ5neKzkBBFGzJhQzR9U0rWxL3kEYYV7ieeZh8hvCfLffhyP2AghYESkJqOa7fg5qAj)\n",
    "\n",
    "The significance level $\\alpha$ is the type-I error: the probability of rejecting the null hypothesis when it is correct. \n",
    "The type-II error is the probability of failing to reject the null when the alternate is correct; this is related to the *power* of the test. \n",
    "\n",
    "**Illustration**: What is the null hypothesis here?\n",
    "![](https://qph.fs.quoracdn.net/main-qimg-a25c9f17379bd7b94719a77686dfb519)\n",
    "Image source: https://effectsizefaq.com/2010/05/31/i-always-get-confused-about-type-i-and-ii-errors-can-you-show-me-something-to-help-me-remember-the-difference/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The $t$-test in action\n",
    "Let us assess the accuracy of one of the ConvNets we saw in Week 2. We will construct $5$ different training-validation splits of the data. \n",
    "We will test for the following:\n",
    "\n",
    "$$\n",
    "H_0: \\text{accuracy} \\le 0.87 \\\\\n",
    "H_1: \\text{accuracy} > 0.87\n",
    "$$\n",
    "\n",
    "We will use a significance level of $\\alpha = 0.05$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from torch.nn.functional import cross_entropy\n",
    "import time\n",
    "import scipy.stats\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the FashionMNIST dataset and divide it into 5 train-val pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FashionMNIST('./data', train=True, download=True)\n",
    "X_train = train_dataset.data # torch tensor of type uint8\n",
    "y_train = train_dataset.targets # torch tensor of type Long\n",
    "\n",
    "X_train = X_train.float()  # convert to float32\n",
    "X_train = X_train.view(-1, 784)\n",
    "mean, std = X_train.mean(axis=0), X_train.std(axis=0)\n",
    "X_train = (X_train - mean[None, :]) / (std[None, :] + 1e-6)  # avoid divide by zero\n",
    "\n",
    "\n",
    "\n",
    "# shuffle the data\n",
    "idxs = np.random.permutation(X_train.shape[0])\n",
    "size = X_train.shape[0]//10\n",
    "\n",
    "Xs = [] \n",
    "ys = []\n",
    "for i in range(10): # 5 train-val pairs\n",
    "    subsample_idxs = idxs[i*size : (i+1)*size]\n",
    "    X = X_train[subsample_idxs]\n",
    "    y = y_train[subsample_idxs]\n",
    "    Xs.append(X)\n",
    "    ys.append(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we write the model and our helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv_ensemble_1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2))\n",
    "        self.conv_ensemble_2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2))\n",
    "        self.fc = torch.nn.Linear(7*7*32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        out = self.conv_ensemble_1(x)\n",
    "        out = self.conv_ensemble_2(out)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "# Some utility functions to compute the objective and the accuracy\n",
    "def compute_objective(model, X, y):\n",
    "    score = model(X)\n",
    "    # PyTorch's function cross_entropy computes the multinomial logistic loss\n",
    "    return cross_entropy(input=score, target=y, reduction='mean') \n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_accuracy(model, X, y):\n",
    "    score = model(X)\n",
    "    predictions = torch.argmax(score, axis=1)  # class with highest score is predicted\n",
    "    return (predictions == y).sum() * 1.0 / y.shape[0]\n",
    "\n",
    "def sgd_one_pass(model, X, y, learning_rate, verbose=False):\n",
    "    num_examples = X.shape[0]\n",
    "    average_loss = 0.0\n",
    "    for i in range(num_examples):\n",
    "        idx = np.random.choice(X.shape[0])\n",
    "        # compute the objective. \n",
    "        # Note: This function requires X to be of shape (n,d). In this case, n=1 \n",
    "        objective = compute_objective(model, X[idx:idx+1], y[idx:idx+1]) \n",
    "        average_loss = 0.99 * average_loss + 0.01 * objective.item()\n",
    "        if verbose and (i+1) % 100 == 0:\n",
    "            print(average_loss)\n",
    "        \n",
    "        # compute the gradient using automatic differentiation\n",
    "        gradients = torch.autograd.grad(outputs=objective, inputs=model.parameters())\n",
    "        \n",
    "        # perform SGD update. IMPORTANT: Make the update inplace!\n",
    "        for (w, g) in zip(model.parameters(), gradients):\n",
    "            w.data -= learning_rate * g.data\n",
    "      \n",
    "    \n",
    "from tqdm.auto import trange # range + progress bar\n",
    "def sgd_n_passes(X_train, y_train, X_val, y_val, n_passes, learning_rate):\n",
    "    model = ConvNet()\n",
    "    for i in trange(n_passes):\n",
    "        sgd_one_pass(model, X_train, y_train, learning_rate)\n",
    "    return compute_accuracy(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1def96d7da344bd1ba5f77779681568e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77571cf80502482a814b5468abc3d789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf22c7e91854e428bb8390316c2dab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de6121b86ed4a149c70ae3f173817f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cdb121428314026bdffd5c57bc065c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies = []\n",
    "for i in range(5):\n",
    "    print(f'Starting run {i+1}')\n",
    "    X_train, y_train = Xs[2*i], ys[2*i]\n",
    "    X_val, y_val = Xs[2*i+1], ys[2*i+1]\n",
    "    acc = sgd_n_passes(X_train, y_train, X_val, y_val, n_passes=30, learning_rate=2.5e-3)\n",
    "    accuracies.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = np.asarray(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87866664, 0.8703333 , 0.8821667 , 0.88633335, 0.8715    ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic: 2.5435465167761073\t threshold: 2.13184678133629\n",
      "Reject the null\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05  # significance level\n",
    "a_0 = 0.87 # accuracy level we are testing for\n",
    "K = accuracies.shape[0]\n",
    "m = np.mean(accuracies)\n",
    "s = np.std(accuracies, ddof=1)  # divide by K-1\n",
    "\n",
    "# Compute the test statistic\n",
    "T =  np.sqrt(K) * (m - a_0) / s\n",
    "threshold = scipy.stats.t(df=K-1).ppf(1-alpha)  # 1-alpha quantile of t_{K-1}\n",
    "\n",
    "print(f'Test statistic: {T}\\t threshold: {threshold}')\n",
    "\n",
    "if T > threshold:\n",
    "    print('Reject the null')\n",
    "else:\n",
    "    print('Fail to reject the null')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can work through what we would have gotten if were to test for \n",
    "accuracy being at least 88%. \n",
    "\n",
    "**NOTE**: We must determine the hypotheses before running the task. We are not supposed to adaptively change the test depending on the results. This is only \"a simulation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic: -0.7174156594326454\t threshold: 2.13184678133629\n",
      "Fail to reject the null\n"
     ]
    }
   ],
   "source": [
    "a_0 = 0.88 \n",
    "# Compute the test statistic\n",
    "T =  T = np.sqrt(K) * (m - a_0) / s\n",
    "threshold = scipy.stats.t(df=K-1).ppf(1-alpha)  # 1-alpha quantile of t_{K-1}\n",
    "\n",
    "print(f'Test statistic: {T}\\t threshold: {threshold}')\n",
    "\n",
    "if T > threshold:\n",
    "    print('Reject the null')\n",
    "else:\n",
    "    print('Fail to reject the null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data598 wi22",
   "language": "python",
   "name": "data598"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
